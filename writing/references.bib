
@article{linde-domingo_geometry_2024,
	title = {Geometry of visuospatial working memory information in miniature gaze patterns},
	volume = {8},
	copyright = {2023 The Author(s)},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-023-01737-z},
	doi = {10.1038/s41562-023-01737-z},
	abstract = {Stimulus-dependent eye movements have been recognized as a potential confound in decoding visual working memory information from neural signals. Here we combined eye-tracking with representational geometry analyses to uncover the information in miniature gaze patterns while participants (n = 41) were cued to maintain visual object orientations. Although participants were discouraged from breaking fixation by means of real-time feedback, small gaze shifts ({\textless}1°) robustly encoded the to-be-maintained stimulus orientation, with evidence for encoding two sequentially presented orientations at the same time. The orientation encoding on stimulus presentation was object-specific, but it changed to a more object-independent format during cued maintenance, particularly when attention had been temporarily withdrawn from the memorandum. Finally, categorical reporting biases increased after unattended storage, with indications of biased gaze geometries already emerging during the maintenance periods before behavioural reporting. These findings disclose a wealth of information in gaze patterns during visuospatial working memory and indicate systematic changes in representational format when memory contents have been unattended.},
	language = {en},
	number = {2},
	urldate = {2024-08-19},
	journal = {Nature Human Behaviour},
	author = {Linde-Domingo, Juan and Spitzer, Bernhard},
	month = feb,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Human behaviour, read, Learning and memory, Cognitive neuroscience},
	pages = {336--348},
	file = {Full Text PDF:/Users/siy009/Zotero/storage/MRHDPP8D/Linde-Domingo and Spitzer - 2024 - Geometry of visuospatial working memory informatio.pdf:application/pdf},
}

@article{daquino_eye_2023,
	title = {Eye movements during motor imagery and execution reveal different visuomotor control strategies in manual interception},
	volume = {60},
	issn = {0048-5772, 1469-8986},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/psyp.14401},
	doi = {10.1111/psyp.14401},
	abstract = {Abstract
            Previous research has investigated the degree of congruency in gaze metrics between action execution (AE) and motor imagery (MI) for similar manual tasks. Although eye movement dynamics seem to be limited to relatively simple actions toward static objects, there is little evidence of how gaze parameters change during imagery as a function of more dynamic spatial and temporal task demands. This study examined the similarities and differences in eye movements during AE and MI for an interception task. Twenty‐four students were asked to either mentally simulate or physically intercept a moving target on a computer display. Smooth pursuit, saccades, and response time were compared between the two conditions. The results show that MI was characterized by higher smooth pursuit gain and duration while no meaningful differences were found in the other parameters. The findings indicate that eye movements during imagery are not simply a duplicate of what happens during actual performance. Instead, eye movements appear to vary as a function of the interaction between visuomotor control strategies and task demands.
          , 
            Even though cognitive and perceptual processes during motor imagery (MI) seem to be functionally equivalent to those during execution, they are not the same. Our research sheds light on the mechanisms underlying perceptual sharedness and challenges previous conclusions by showing that eye movements during MI are influenced by the unique interaction of prospective and predictive models of action control.},
	language = {en},
	number = {12},
	urldate = {2024-09-04},
	journal = {Psychophysiology},
	author = {D'Aquino, Alessio and Frank, Cornelia and Hagan, John Elvis and Schack, Thomas},
	month = dec,
	year = {2023},
	pages = {e14401},
	annote = {[TLDR] The findings indicate that eye movements during imagery are not simply a duplicate of what happens during actual performance, and appear to vary as a function of the interaction between visuomotor control strategies and task demands.},
	file = {Full Text:/Users/siy009/Zotero/storage/JLFS8UST/D'Aquino et al. - 2023 - Eye movements during motor imagery and execution r.pdf:application/pdf},
}

@article{de_vries_microsaccades_2024,
	title = {Microsaccades {Track} {Location}-{Based} {Object} {Rehearsal} in {Visual} {Working} {Memory}},
	volume = {11},
	issn = {2373-2822},
	doi = {10.1523/ENEURO.0276-23.2023},
	abstract = {Besides controlling eye movements, the brain's oculomotor system has been implicated in the control of covert spatial attention and the rehearsal of spatial information in working memory. We investigated whether the oculomotor system also contributes to rehearsing visual objects in working memory when object location is never asked about. To address this, we tracked the incidental use of locations for mnemonic rehearsal via directional biases in microsaccades while participants maintained two visual objects (colored oriented gratings) in working memory. By varying the stimulus configuration (horizontal, diagonal, and vertical) at encoding, we could quantify whether microsaccades were more aligned with the configurational axis of the memory contents, as opposed to the orthogonal axis. Experiment 1 revealed that microsaccades continued to be biased along the axis of the memory content several seconds into the working memory delay. In Experiment 2, we confirmed that this directional microsaccade bias was specific to memory demands, ruling out lingering effects from passive and attentive encoding of the same visual objects in the same configurations. Thus, by studying microsaccade directions, we uncover oculomotor-driven rehearsal of visual objects in working memory through their associated locations.},
	language = {eng},
	number = {1},
	journal = {eNeuro},
	author = {de Vries, Eelke and van Ede, Freek},
	month = jan,
	year = {2024},
	pmid = {38176905},
	pmcid = {PMC10849020},
	keywords = {read, attention, Attention, visual working memory, Humans, Memory, Short-Term, Visual Perception, Saccades, Eye Movements, eye movements, microsaccades, oculomotor system, Space Perception, task-dependent},
	pages = {ENEURO.0276--23.2023},
	file = {Full Text:/Users/siy009/Zotero/storage/BE5GB8AA/de Vries and van Ede - 2024 - Microsaccades Track Location-Based Object Rehearsa.pdf:application/pdf},
}

@article{heremans_eyes_2008,
	title = {The eyes as a mirror of our thoughts: {Quantification} of motor imagery of goal-directed movements through eye movement registration},
	volume = {187},
	issn = {0166-4328},
	shorttitle = {The eyes as a mirror of our thoughts},
	url = {https://www.sciencedirect.com/science/article/pii/S0166432807005049},
	doi = {10.1016/j.bbr.2007.09.028},
	abstract = {It has been suggested that motor imagery possesses a range of useful applications in sport as well as in rehabilitation. Until now, research in this field has been hampered by the lack of an objective method to monitor the subjects’ participation in the task. In this present study, a new approach to quantifying motor imagery of goal-directed hand movements by means of eye movement registration is examined. Eye movements of 15 right-handed subjects were recorded using EOG during both physical execution and visual motor imagery of a cyclical aiming task, performed at three different inter-target distances. We found that 89\% of subjects made task-related eye movements during imagery with the eyes open and 84\% of participants also did so during imagery with the eyes closed. Both the number and amplitude of the eye movements during imagery closely resembled those of eye movements made during physical execution of the task. This indicates that the coupling between neural patterns for eye and hand movements remains intact when hand movements are merely imagined as opposed to being physically executed. Therefore, eye movement recordings may be used as an objective technique to evaluate subjects’ compliance, motor imagery ability, and spatial accuracy.},
	number = {2},
	urldate = {2024-09-04},
	journal = {Behavioural Brain Research},
	author = {Heremans, Elke and Helsen, Werner F. and Feys, Peter},
	month = mar,
	year = {2008},
	keywords = {skimmed, Eye movements, Electro-oculography, Eye–hand coordination, Hand movements, Motor imagery, Visual imagery},
	pages = {351--360},
	file = {Full Text:/Users/siy009/Zotero/storage/FADNEW4P/Heremans et al. - 2008 - The eyes as a mirror of our thoughts Quantificati.pdf:application/pdf;ScienceDirect Snapshot:/Users/siy009/Zotero/storage/538WV3KC/S0166432807005049.html:text/html},
}


@article{christophelCorticalSpecializationAttended2018,
	title = {Cortical specialization for attended versus unattended working memory},
	volume = {21},
	copyright = {2018 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0094-4},
	doi = {10.1038/s41593-018-0094-4},
	abstract = {Items held in working memory can be either attended or not, depending on their current behavioral relevance. It has been suggested that unattended contents might be solely retained in an activity-silent form. Instead, we demonstrate here that encoding unattended contents involves a division of labor. While visual cortex only maintains attended items, intraparietal areas and the frontal eye fields represent both attended and unattended items.},
	language = {en},
	number = {4},
	urldate = {2025-02-28},
	journal = {Nature Neuroscience},
	author = {Christophel, Thomas B. and Iamshchinina, Polina and Yan, Chang and Allefeld, Carsten and Haynes, John-Dylan},
	month = apr,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Attention, Psychology, Working memory},
	pages = {494--496},
	file = {Full Text PDF:/Users/sihanyang/Zotero/storage/LPT269XA/Christophel et al. - 2018 - Cortical specialization for attended versus unatte.pdf:application/pdf},
}
