{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:51.892524Z",
     "iopub.status.busy": "2025-03-09T22:29:51.891334Z",
     "iopub.status.idle": "2025-03-09T22:29:51.921513Z",
     "shell.execute_reply": "2025-03-09T22:29:51.920138Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:51.928072Z",
     "iopub.status.busy": "2025-03-09T22:29:51.927370Z",
     "iopub.status.idle": "2025-03-09T22:29:54.372423Z",
     "shell.execute_reply": "2025-03-09T22:29:54.371455Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.377101Z",
     "iopub.status.busy": "2025-03-09T22:29:54.376554Z",
     "iopub.status.idle": "2025-03-09T22:29:54.397217Z",
     "shell.execute_reply": "2025-03-09T22:29:54.396390Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_n_dir_up(path, n):\n",
    "    for _ in range(n):\n",
    "        path = os.path.dirname(path)\n",
    "    return path\n",
    "\n",
    "CUR_PATH= os.path.abspath(\"__file__\")\n",
    "sys.path.append(os.path.join(get_n_dir_up(CUR_PATH, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.401062Z",
     "iopub.status.busy": "2025-03-09T22:29:54.400652Z",
     "iopub.status.idle": "2025-03-09T22:29:54.419387Z",
     "shell.execute_reply": "2025-03-09T22:29:54.418594Z"
    }
   },
   "outputs": [],
   "source": [
    "#experiment specific params\n",
    "\n",
    "EVENTS_ARR = [\n",
    "    ('fixation', 1000),\n",
    "    ('stimulus1', 250),\t\n",
    "    ('cue1', 500),\t\n",
    "    ('mask1', 500),\n",
    "    ('shortDelay', 1000),\n",
    "    ('stimulus2', 250),\n",
    "    ('cue2', 500),\n",
    "    ('mask2', 500),\n",
    "    ('longDelay', 5000),\n",
    "]\n",
    "\n",
    "included = np.sum([t[1] for t in EVENTS_ARR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.423142Z",
     "iopub.status.busy": "2025-03-09T22:29:54.422730Z",
     "iopub.status.idle": "2025-03-09T22:29:54.443675Z",
     "shell.execute_reply": "2025-03-09T22:29:54.442886Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.eye_trial import generate_events\n",
    "from utils.eye_trial import generate_stim_phases\n",
    "\n",
    "EVENTS = generate_events()\n",
    "ALL_STIM_PHASES = generate_stim_phases(EVENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.447491Z",
     "iopub.status.busy": "2025-03-09T22:29:54.447082Z",
     "iopub.status.idle": "2025-03-09T22:29:54.466356Z",
     "shell.execute_reply": "2025-03-09T22:29:54.465559Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_cleaned_data(behavior_folder, gaze_folder, filename):\n",
    "    psyFull_path = f'{behavior_folder}/{filename}.csv'\n",
    "    psyFull = None\n",
    "    if os.path.exists(psyFull_path):\n",
    "        psyFull = pd.read_csv(psyFull_path)\n",
    "        psyFull = psyFull.drop(\n",
    "            columns=[col for col in psyFull.columns if col.startswith(\"Unnamed\")])\n",
    "        \n",
    "    gazeClean_path = f'{gaze_folder}/{filename}.csv'\n",
    "    gazeClean = None\n",
    "    if os.path.exists(gazeClean_path):\n",
    "        gazeClean = pd.read_csv(gazeClean_path)\n",
    "        gazeClean = gazeClean.drop(\n",
    "            columns=[col for col in gazeClean.columns if col.startswith(\"Unnamed\")])\n",
    "\n",
    "    return psyFull, gazeClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Feature Extractor\n",
    "\n",
    "- mean gaze position\n",
    "- saccade direction\n",
    "- 1d angles of gaze position\n",
    "- 2d heat maps of gaze position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.470294Z",
     "iopub.status.busy": "2025-03-09T22:29:54.469885Z",
     "iopub.status.idle": "2025-03-09T22:29:54.492053Z",
     "shell.execute_reply": "2025-03-09T22:29:54.491263Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from utils.eye_data import XYData\n",
    "\n",
    "class BaseEyeFeatureExtractor(ABC):\n",
    "    def __init__(self, settings):\n",
    "        self.settings = settings\n",
    "        self.initialize()\n",
    "\n",
    "    def center_normalize(self, all_xs, all_ys, norm_xs, norm_ys, center_align_setting):\n",
    "        center = center_align_setting['center']\n",
    "        norm_center = center\n",
    "        if center_align_setting.get('median_align', False):\n",
    "            # instead we use subject median position\n",
    "            timepoint_align = center_align_setting.get(\n",
    "                'timepoint_align', False)\n",
    "            if timepoint_align:\n",
    "                center = (\n",
    "                    np.median(all_xs, axis=0).astype(int),\n",
    "                    np.median(all_ys, axis=0).astype(int)\n",
    "                )\n",
    "                norm_center = (\n",
    "                    np.median(norm_xs, axis=0).astype(int),\n",
    "                    np.median(norm_ys, axis=0).astype(int)\n",
    "                )\n",
    "            else:\n",
    "                center = (int(np.median(norm_xs)), int(np.median(norm_ys)))\n",
    "                norm_center = center\n",
    "        all_xs, all_ys = all_xs - center[0], all_ys - center[1]\n",
    "        norm_xs, norm_ys = norm_xs - norm_center[0], norm_ys - norm_center[1]\n",
    "\n",
    "        return all_xs, all_ys, norm_xs, norm_ys\n",
    "\n",
    "    @abstractmethod\n",
    "    def initialize(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_subject_features(self, source_data: XYData, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean gaze position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.495890Z",
     "iopub.status.busy": "2025-03-09T22:29:54.495586Z",
     "iopub.status.idle": "2025-03-09T22:29:54.518416Z",
     "shell.execute_reply": "2025-03-09T22:29:54.517582Z"
    }
   },
   "outputs": [],
   "source": [
    "class GazeMeanExtractor(BaseEyeFeatureExtractor):\n",
    "    def initialize(self):\n",
    "        pass\n",
    "\n",
    "    def bin_data(self, data):\n",
    "        time_bin = self.settings['time_binning']['timebin_size']\n",
    "        # assuming the last dimension is time dimension\n",
    "        shape_original = data.shape\n",
    "        t_original = shape_original[-1]\n",
    "        n_bins = t_original // time_bin\n",
    "        data = data[..., :n_bins * time_bin]\n",
    "        data = data.reshape(*shape_original[:-1], n_bins, time_bin)\n",
    "        return data\n",
    "\n",
    "    def convert_to_avg_position(self, xs, ys):\n",
    "        # binning\n",
    "        xs = self.bin_data(xs)\n",
    "        ys = self.bin_data(ys)\n",
    "\n",
    "        # compute mean position\n",
    "        xs = np.mean(xs, axis=-1)\n",
    "        ys = np.mean(ys, axis=-1)\n",
    "\n",
    "        results = np.stack([xs, ys], axis=-1)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "    def get_subject_features(self, source_data: XYData, norm_phases, trial_ids):\n",
    "        # apply centering\n",
    "        all_xs, all_ys = source_data.read(trial_ids=trial_ids)\n",
    "        norm_xs, norm_ys = source_data.read_phase(phases=norm_phases, trial_ids=trial_ids)\n",
    "        center_align_setting = self.settings['center_align']\n",
    "\n",
    "        # converted position to z score\n",
    "        all_xs, all_ys, norm_xs, norm_ys = self.center_normalize(\n",
    "            all_xs, all_ys, norm_xs, norm_ys, center_align_setting)\n",
    "        \n",
    "        if center_align_setting['z_score']:            \n",
    "            # first apply boundary\n",
    "            radius = center_align_setting['z_score']['radius'] \n",
    "            norm_xs, norm_ys = np.clip(norm_xs, -radius, radius), np.clip(norm_ys, -radius, radius)\n",
    "            \n",
    "            # then normalization\n",
    "            mean_norm_xs, mean_norm_ys = np.mean(norm_xs), np.mean(norm_ys)\n",
    "            std_norm_xs, std_norm_ys = np.std(norm_xs), np.std(norm_ys)\n",
    "            norm_xs, norm_ys = (norm_xs - mean_norm_xs) / std_norm_xs, (norm_ys - mean_norm_ys) / std_norm_ys\n",
    "            all_xs, all_ys = (all_xs - mean_norm_xs) / std_norm_xs, (all_ys - mean_norm_ys) / std_norm_ys\n",
    "\n",
    "            # finally clip to remove too large values\n",
    "            cap_ratio = center_align_setting['z_score']['cap_ratio']\n",
    "            all_xs, all_ys = np.clip(all_xs, -cap_ratio, cap_ratio), np.clip(all_ys, -cap_ratio, cap_ratio)\n",
    "\n",
    "        # compute mean position\n",
    "        results = self.convert_to_avg_position(all_xs, all_ys)\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1d feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.522357Z",
     "iopub.status.busy": "2025-03-09T22:29:54.522055Z",
     "iopub.status.idle": "2025-03-09T22:29:54.798436Z",
     "shell.execute_reply": "2025-03-09T22:29:54.797285Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.eye_feature import SaccadeAngleStats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "class GazeAngleFeatureExtractor(BaseEyeFeatureExtractor):\n",
    "    def initialize(self):\n",
    "        self.GazeAngleHelper = SaccadeAngleStats(self.settings)\n",
    "\n",
    "    def bin_data(self, data):\n",
    "        time_bin = self.settings['time_binning']['timebin_size']\n",
    "        # assuming the last dimension is time dimension\n",
    "        shape_original = data.shape\n",
    "        t_original = shape_original[-1]\n",
    "        n_bins = t_original // time_bin\n",
    "        data = data[..., :n_bins * time_bin]\n",
    "        data = data.reshape(*shape_original[:-1], n_bins, time_bin)\n",
    "        return data\n",
    "\n",
    "    def angle_to_ids(self, angles):\n",
    "        n_angle_bins = self.settings['angle_to_id']['n_angle_bins']\n",
    "        to_fold = self.settings['angle_to_id']['to_fold']\n",
    "        epoch = 180 if to_fold else 360\n",
    "        angles = angles % epoch\n",
    "        angle_bin_size = epoch / n_angle_bins \n",
    "        angle_bin_ids = (angles + angle_bin_size/2) / angle_bin_size\n",
    "        angle_bin_ids = angle_bin_ids.astype(int) % n_angle_bins\n",
    "        # print(angles[:2, :2, :3], angle_bin_ids[:2, :2, :3])\n",
    "        return angle_bin_ids\n",
    "    \n",
    "    def batch_process_1dids(self, state_ids, weights):\n",
    "        filter_zero = self.settings['occurence']['filter_zero']\n",
    "        n_states = self.settings['angle_to_id']['n_angle_bins']\n",
    "        \n",
    "        assert len(state_ids.shape) == 3 \n",
    "        n_trials, n_time_bins, timebin_size = state_ids.shape\n",
    "        \n",
    "        # compute number of occurence each trial, each time point\n",
    "        occurences = None\n",
    "        if filter_zero:\n",
    "            occurences = np.sum(weights>0, axis=-1, keepdims=True)\n",
    "        else:\n",
    "            occurences = np.ones((n_trials, n_time_bins, 1)) * timebin_size\n",
    "\n",
    "        # aggregate\n",
    "        # output: n_trials * n_time_bins * n_states\n",
    "        results = np.zeros((n_trials, n_time_bins, n_states))\n",
    "        trial_indices, time_indices, state_indices = np.meshgrid(\n",
    "            np.arange(n_trials), np.arange(n_time_bins), np.arange(timebin_size), indexing='ij'\n",
    "        )\n",
    "        np.add.at(\n",
    "            results, \n",
    "            (trial_indices.ravel(), time_indices.ravel(), state_ids.ravel()), \n",
    "            weights.ravel())\n",
    "\n",
    "        # normalize\n",
    "        occ_non_zero = np.where(occurences>0, occurences, 1)\n",
    "        results = results / occ_non_zero\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def convert_collapsed_1dvec(self, xs, ys):\n",
    "        _, angles, mag_weights = self.GazeAngleHelper.convert_subject_occurence_to_angle_weight(xs, ys)\n",
    "        # sum everything up\n",
    "        angle_ids = self.angle_to_ids(angles)\n",
    "        n_states = self.settings['angle_to_id']['n_angle_bins']\n",
    "        h = np.zeros(n_states)\n",
    "        np.add.at(h, angle_ids.flatten(), mag_weights.flatten())\n",
    "        # normalization: count number of occurences\n",
    "        filter_zero = self.settings['occurence']['filter_zero']\n",
    "        n_occurences = np.sum(mag_weights > 0).astype(int) if filter_zero else np.size(xs)\n",
    "        h = h / n_occurences\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def convert_eyedata_1dvec(self, xs, ys):\n",
    "        # convert all angle, mag for each timepoint\n",
    "        _, angles, mag_weights = self.GazeAngleHelper.convert_subject_occurence_to_angle_weight(xs, ys)\n",
    "        # print('convert to angle', xs[:2, :2], ys[:2, :2], angles[:2, :2])\n",
    "    \n",
    "        # aggreagte each time bin\n",
    "        angles_binned = self.bin_data(angles)\n",
    "        mag_weights_binned = self.bin_data(mag_weights)\n",
    "\n",
    "        # convert angle to angle bin id\n",
    "        angle_ids_binned = self.angle_to_ids(angles_binned)\n",
    "\n",
    "        # now compute the collapsed\n",
    "        results = self.batch_process_1dids(angle_ids_binned, mag_weights_binned)\n",
    "\n",
    "        return results\n",
    "        \n",
    "    def get_subject_features(self, source_data: XYData, norm_phases, trial_ids):\n",
    "        # apply center normalization if needed\n",
    "        all_xs, all_ys = source_data.read(trial_ids=trial_ids)\n",
    "        norm_xs, norm_ys = source_data.read_phase(phases=norm_phases, trial_ids=trial_ids)\n",
    "        center_align_setting = self.settings['center_align']\n",
    "\n",
    "        # first move everything to the center\n",
    "        all_xs, all_ys, norm_xs, norm_ys = self.center_normalize(\n",
    "            all_xs, all_ys, norm_xs, norm_ys, center_align_setting)            \n",
    "        \n",
    "        # NOTE: input data should have been subject-normalized\n",
    "        results = self.convert_eyedata_1dvec(all_xs, all_ys)\n",
    "\n",
    "        # also compute the subject bias, using the norm_phases\n",
    "        subj_vec = self.convert_collapsed_1dvec(norm_xs, norm_ys)\n",
    "        \n",
    "        # normalization: remove subject bias\n",
    "        results = results - subj_vec\n",
    "\n",
    "        # finally, apply smoothing\n",
    "        smoothing_params = self.settings.get('smoothing')\n",
    "        if smoothing_params is not None:\n",
    "            results = gaussian_filter1d(\n",
    "                results, \n",
    "                sigma=smoothing_params['sigma'], \n",
    "                mode='wrap', axis=-1)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2d feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.803902Z",
     "iopub.status.busy": "2025-03-09T22:29:54.803126Z",
     "iopub.status.idle": "2025-03-09T22:29:54.836780Z",
     "shell.execute_reply": "2025-03-09T22:29:54.835779Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.eye_stats import compute_vecmap\n",
    "from utils.eye_preprocess import convert_movement_to_angle\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "class Map2dHelper:\n",
    "    def __init__(self, settings):\n",
    "        # process settings\n",
    "        self.min_mag = settings['min_mag']\n",
    "        self.max_mag = settings['max_mag']\n",
    "        self.smoothing_params = settings['smoothing']\n",
    "        self.vec_map_params = settings['vecmap']\n",
    "\n",
    "    def filter_by_mags(self, xs, ys):\n",
    "        # filter out too tiny or too large magnitude\n",
    "        _, mags = convert_movement_to_angle(xs, ys, compute_mag=True)\n",
    "        mag_mask = (mags >= self.min_mag) & (mags <= self.max_mag)\n",
    "        xs = xs[mag_mask]\n",
    "        ys = ys[mag_mask]\n",
    "        return xs, ys\n",
    "\n",
    "    def smooth_vecmap(self, vecmap):\n",
    "        sigma = self.smoothing_params['sigma']\n",
    "        vecmap = gaussian_filter(vecmap, sigma=sigma, mode='constant', cval=0)\n",
    "        return vecmap\n",
    "\n",
    "    def data_to_vecmaps(self, xs, ys):\n",
    "        vecmap_settings = self.vec_map_params\n",
    "        h, _, _ = compute_vecmap(xs, ys, **vecmap_settings)\n",
    "        return h\n",
    "    \n",
    "    def convert_xy_to_feature(self, xs, ys):\n",
    "        # filteirng\n",
    "        xs, ys = self.filter_by_mags(xs, ys)\n",
    "        # 2d map\n",
    "        vecmap = self.data_to_vecmaps(xs, ys)\n",
    "        # smoothing\n",
    "        vecmap = self.smooth_vecmap(vecmap)\n",
    "        # flattening\n",
    "        vec = vecmap.flatten()\n",
    "        # normalization\n",
    "        vec_sum = np.sum(vec)\n",
    "        vec_sum = vec_sum if vec_sum > 0 else 1\n",
    "        vec = vec / vec_sum\n",
    "        return vec\n",
    "\n",
    "class GazeHeatmapFeatureExtractor(BaseEyeFeatureExtractor):\n",
    "    def initialize(self):\n",
    "        self.vecmap_helper = Map2dHelper(self.settings['2dhist'])\n",
    "\n",
    "    def bin_data(self, data):\n",
    "        time_bin = self.settings['time_binning']['timebin_size']\n",
    "        # assuming the last dimension is time dimension\n",
    "        shape_original = data.shape\n",
    "        t_original = shape_original[-1]\n",
    "        n_bins = t_original // time_bin\n",
    "        data = data[..., :n_bins * time_bin]\n",
    "        data = data.reshape(*shape_original[:-1], n_bins, time_bin)\n",
    "        return data\n",
    "\n",
    "    def convert_collapsed_vec(self, xs, ys):\n",
    "        xs = xs.flatten()\n",
    "        ys = ys.flatten()\n",
    "        vec = self.vecmap_helper.convert_xy_to_feature(xs, ys)\n",
    "        return vec\n",
    "\n",
    "    def convert_bulk_vec(self, xs, ys):\n",
    "        # aggreagte each time bin\n",
    "        xs = self.bin_data(xs)\n",
    "        ys = self.bin_data(ys)\n",
    "        n_trials, n_time_bins, timebin_size = xs.shape\n",
    "        # aggregate features\n",
    "        results = []\n",
    "        for trial_id in range(n_trials):\n",
    "            trial_result = []\n",
    "            for tid in range(n_time_bins):\n",
    "                tresult = self.convert_collapsed_vec(\n",
    "                    xs[trial_id][tid],\n",
    "                    ys[trial_id][tid])\n",
    "                trial_result.append(tresult)\n",
    "            results.append(trial_result)\n",
    "        results = np.array(results)\n",
    "        return results\n",
    "        \n",
    "    def get_subject_features(self, source_data: XYData, norm_phases, trial_ids):\n",
    "        # apply center normalization if needed\n",
    "        all_xs, all_ys = source_data.read(trial_ids=trial_ids)\n",
    "        norm_xs, norm_ys = source_data.read_phase(phases=norm_phases, trial_ids=trial_ids)\n",
    "        center_align_setting = self.settings['center_align']\n",
    "\n",
    "        # first move everything to the center\n",
    "        all_xs, all_ys, norm_xs, norm_ys = self.center_normalize(\n",
    "            all_xs, all_ys, norm_xs, norm_ys, center_align_setting)           \n",
    "        \n",
    "        # NOTE: input data should have been subject-normalized\n",
    "        results = self.convert_bulk_vec(all_xs, all_ys)\n",
    "\n",
    "        # also compute the subject bias, using the norm_phases\n",
    "        subj_vec = self.convert_collapsed_vec(norm_xs, norm_ys)\n",
    "        \n",
    "        # normalization: remove subject bias\n",
    "        results = results - subj_vec\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**comment**: to get the version not align at each timepont, just comment out 'timepoint_align' (but for feature extraction we need to set it true to address the shifting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.841094Z",
     "iopub.status.busy": "2025-03-09T22:29:54.840601Z",
     "iopub.status.idle": "2025-03-09T22:29:54.863466Z",
     "shell.execute_reply": "2025-03-09T22:29:54.862661Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean position\n",
    "DEFAULT_MEAN_POS_SETTINGS = {\n",
    "    'center_align' : {\n",
    "        'center': (960, 540),\n",
    "        'median_align': True,\n",
    "        'timepoint_align': True,\n",
    "        'z_score': {\n",
    "            'radius': 200,\n",
    "            'cap_ratio': 4,\n",
    "        },\n",
    "    },\n",
    "    'time_binning': {\n",
    "        'timebin_size': 50,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.867039Z",
     "iopub.status.busy": "2025-03-09T22:29:54.866635Z",
     "iopub.status.idle": "2025-03-09T22:29:54.885350Z",
     "shell.execute_reply": "2025-03-09T22:29:54.884570Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1d\n",
    "DEFAULT_1D_VEC_SETTINGS = {\n",
    "    'occurence': {\n",
    "        'n_angle_bins':360,\n",
    "        'n_mag_bins': 10,\n",
    "        'min_mag_thresh': 15,\n",
    "        'max_mag_thresh': 150,\n",
    "        'log_transform': False,\n",
    "        'filter_zero': False,\n",
    "    }, # how to filter event data\n",
    "    'angle_to_id': {\n",
    "        'n_angle_bins': 30,\n",
    "        'to_fold': False,\n",
    "    }, # how to convert angle to state id\n",
    "    'time_binning': {\n",
    "        'timebin_size': 50,\n",
    "    },\n",
    "    'dist_metric': 'cos',\n",
    "    'center_align' : {\n",
    "        'center': (960, 540),\n",
    "        'median_align': True,\n",
    "        'timepoint_align': True,\n",
    "    },\n",
    "    'smoothing': {\n",
    "        'sigma': 2,\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.888811Z",
     "iopub.status.busy": "2025-03-09T22:29:54.888409Z",
     "iopub.status.idle": "2025-03-09T22:29:54.905985Z",
     "shell.execute_reply": "2025-03-09T22:29:54.905311Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_2D_VEC_SETTINGS = {\n",
    "    '2dhist': { \n",
    "        'min_mag': 15,\n",
    "        'max_mag': 300,\n",
    "        'vecmap': {\n",
    "            'x_center': 0,\n",
    "            'y_center': 0,\n",
    "            'x_radius': 150, # 80,\n",
    "            'y_radius': 150, # 80,\n",
    "            'n_bins': 15, # 20,\n",
    "            'log_transform': False,\n",
    "        },\n",
    "        'smoothing': {\n",
    "            'sigma': 3,\n",
    "        },\n",
    "    },\n",
    "    'time_binning': {\n",
    "        'timebin_size': 50,\n",
    "    },\n",
    "    'dist_metric': 'cos', # 'euc',\n",
    "    'center_align' : {\n",
    "        'center': (960, 540),\n",
    "        'median_align': True,\n",
    "        'timepoint_align': True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.909031Z",
     "iopub.status.busy": "2025-03-09T22:29:54.908681Z",
     "iopub.status.idle": "2025-03-09T22:29:54.924268Z",
     "shell.execute_reply": "2025-03-09T22:29:54.923598Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = GazeMeanExtractor(DEFAULT_MEAN_POS_SETTINGS)\n",
    "# feature_extractor = GazeAngleFeatureExtractor(DEFAULT_1D_VEC_SETTINGS)\n",
    "# feature_extractor = GazeHeatmapFeatureExtractor(DEFAULT_2D_VEC_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.927178Z",
     "iopub.status.busy": "2025-03-09T22:29:54.926848Z",
     "iopub.status.idle": "2025-03-09T22:29:54.940934Z",
     "shell.execute_reply": "2025-03-09T22:29:54.940302Z"
    }
   },
   "outputs": [],
   "source": [
    "NORM_PHASES = [\n",
    "    ALL_STIM_PHASES[0]['display'],\n",
    "    ALL_STIM_PHASES[0]['delay'],\n",
    "    ALL_STIM_PHASES[1]['display'],\n",
    "    ALL_STIM_PHASES[1]['delay'],\n",
    "] # define the phasese we use for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.943593Z",
     "iopub.status.busy": "2025-03-09T22:29:54.943278Z",
     "iopub.status.idle": "2025-03-09T22:29:54.958134Z",
     "shell.execute_reply": "2025-03-09T22:29:54.957557Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_one_subject_feature(fe: BaseEyeFeatureExtractor, eyedata, df, subj):\n",
    "    subj_df = df[df['participant'] == subj]\n",
    "    subj_trial_ids_temp = subj_df['TRIALID'].to_numpy()\n",
    "\n",
    "    # read subject trial gaze data\n",
    "    subj_xs, subj_ys, subj_trial_mask = eyedata.read(\n",
    "        trial_ids=subj_trial_ids_temp, get_trial_mask=True)\n",
    "    subj_trial_ids = subj_trial_ids_temp[subj_trial_mask]\n",
    "    subj_eyedata = XYData(subj_xs, subj_ys, subj_trial_ids)\n",
    "\n",
    "    # collect feature data\n",
    "    subj_features = fe.get_subject_features(\n",
    "        source_data=subj_eyedata, norm_phases=NORM_PHASES, trial_ids=None)\n",
    "\n",
    "    # read valid ids\n",
    "    subj_df = subj_df[subj_trial_mask]\n",
    "    subj_trial_ids = subj_trial_ids_temp[subj_trial_mask]\n",
    "\n",
    "    return subj_features, subj_trial_mask, subj_df, subj_trial_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.960829Z",
     "iopub.status.busy": "2025-03-09T22:29:54.960499Z",
     "iopub.status.idle": "2025-03-09T22:29:54.975631Z",
     "shell.execute_reply": "2025-03-09T22:29:54.975013Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.path.join(get_n_dir_up(CUR_PATH, 3), 'data')\n",
    "DATA_LARGE_FOLDER = os.path.join(get_n_dir_up(CUR_PATH, 4), 'data', 'pilot')\n",
    "DEFAULT_BEHAV_FOLDER = os.path.join(DATA_FOLDER, 'behavior', 'batches')\n",
    "DEFAULT_GAZE_FOLDER = os.path.join(DATA_LARGE_FOLDER, 'gaze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:54.978391Z",
     "iopub.status.busy": "2025-03-09T22:29:54.978078Z",
     "iopub.status.idle": "2025-03-09T22:29:54.997061Z",
     "shell.execute_reply": "2025-03-09T22:29:54.996171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['908to915', '916to922', '927to937', '938to949', '950to952']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(DATA_FOLDER, 'batch.json')) as f:\n",
    "    SUBJ_MAPPING = json.load(f)\n",
    "    SUBJ_DATA_IDS = list(SUBJ_MAPPING.keys())\n",
    "    SUBJ_DATA_IDS.sort()\n",
    "\n",
    "SUBJ_DATA_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:29:55.032032Z",
     "iopub.status.busy": "2025-03-09T22:29:55.031751Z",
     "iopub.status.idle": "2025-03-09T22:30:23.094766Z",
     "shell.execute_reply": "2025-03-09T22:30:23.093947Z"
    }
   },
   "outputs": [],
   "source": [
    "AllPsyFull, AllGazeCleans = [], []\n",
    "AllSubjBatches = []\n",
    "\n",
    "for subj_data_id in SUBJ_DATA_IDS:\n",
    "    psyFull, gazeClean = read_cleaned_data(\n",
    "        DEFAULT_BEHAV_FOLDER, DEFAULT_GAZE_FOLDER, subj_data_id)\n",
    "    \n",
    "    if (psyFull is not None) and (gazeClean is not None):\n",
    "        AllPsyFull.append(psyFull)\n",
    "        AllGazeCleans.append(gazeClean)\n",
    "        AllSubjBatches.append(SUBJ_MAPPING[subj_data_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pad the PsyFull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:23.097947Z",
     "iopub.status.busy": "2025-03-09T22:30:23.097636Z",
     "iopub.status.idle": "2025-03-09T22:30:23.635601Z",
     "shell.execute_reply": "2025-03-09T22:30:23.634755Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_last_resp_stim(row):\n",
    "    if pd.isna(row['resp_1_last_drawing_tend']) and pd.isna(row['resp_2_last_drawing_tend']):\n",
    "        return np.nan\n",
    "    elif pd.isna(row['resp_1_last_drawing_tend']):\n",
    "        return row['stim_2']\n",
    "    elif pd.isna(row['resp_2_last_drawing_tend']):\n",
    "        return row['stim_1']\n",
    "    else:\n",
    "        return row['stim_2'] if row['resp_2_last_drawing_tend'] > row['resp_1_last_drawing_tend'] else row['stim_1']\n",
    "\n",
    "def get_last_response(row):\n",
    "    if pd.isna(row['resp_1_last_drawing_tend']) and pd.isna(row['resp_2_last_drawing_tend']):\n",
    "        return np.nan\n",
    "    elif pd.isna(row['resp_1_last_drawing_tend']):\n",
    "        return row['resp_2']\n",
    "    elif pd.isna(row['resp_2_last_drawing_tend']):\n",
    "        return row['resp_1']\n",
    "    else:\n",
    "        return row['resp_2'] if row['resp_2_last_drawing_tend'] > row['resp_1_last_drawing_tend'] else row['resp_1']\n",
    "\n",
    "for psyFull in AllPsyFull:\n",
    "    # last resp\n",
    "    psyFull['current_last_response'] = psyFull.apply(get_last_response, axis=1)\n",
    "    # stim of last resp\n",
    "    psyFull['current_last_resp_stim'] = psyFull.apply(get_last_resp_stim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:23.639596Z",
     "iopub.status.busy": "2025-03-09T22:30:23.639177Z",
     "iopub.status.idle": "2025-03-09T22:30:23.674437Z",
     "shell.execute_reply": "2025-03-09T22:30:23.673828Z"
    }
   },
   "outputs": [],
   "source": [
    "def copy_from_last_trial(df, src_name, new_name):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['trial'] += 1  # Increment trial to match the next row's trial\n",
    "    df_copy = df_copy.rename(columns={src_name: new_name})\n",
    "\n",
    "    df_copy = df[['participant', 'block', 'trial', src_name]].copy()\n",
    "    df_copy['trial'] += 1  # Increment trial to match the next row's trial\n",
    "    df_copy = df_copy.rename(columns={src_name: new_name})\n",
    "    df = df.merge(df_copy, on=['participant', 'block', 'trial'], how='left')\n",
    "    return df\n",
    "\n",
    "AllPsyFullCopy = []\n",
    "for psyFull in AllPsyFull:\n",
    "    # copy from last trial resp\n",
    "    psyFull = copy_from_last_trial(\n",
    "        psyFull, 'current_last_response', 'prev_last_response')\n",
    "    # copy from last trial stim of last resp\n",
    "    psyFull = copy_from_last_trial(\n",
    "        psyFull, 'current_last_resp_stim', 'prev_last_resp_stim')\n",
    "    # copy from last trial stims\n",
    "    psyFull = copy_from_last_trial(\n",
    "        psyFull, 'stim_1', 'prev_stim_1')\n",
    "    psyFull = copy_from_last_trial(\n",
    "        psyFull, 'stim_2', 'prev_stim_2')\n",
    "    \n",
    "    # merge it\n",
    "    AllPsyFullCopy.append(psyFull)\n",
    "AllPsyFull = AllPsyFullCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:23.677149Z",
     "iopub.status.busy": "2025-03-09T22:30:23.676848Z",
     "iopub.status.idle": "2025-03-09T22:30:23.690772Z",
     "shell.execute_reply": "2025-03-09T22:30:23.690180Z"
    }
   },
   "outputs": [],
   "source": [
    "example_behav_df = AllPsyFull[0]\n",
    "example_gaze_df = AllGazeCleans[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:23.693500Z",
     "iopub.status.busy": "2025-03-09T22:30:23.693199Z",
     "iopub.status.idle": "2025-03-09T22:30:24.329038Z",
     "shell.execute_reply": "2025-03-09T22:30:24.328120Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.eye_data import create_xydata_from_df\n",
    "\n",
    "example_eye_data = create_xydata_from_df(example_gaze_df)\n",
    "subj908_features, subj908_mask, subj908_df, subj908_trial_ids  = read_one_subject_feature(\n",
    "    feature_extractor, example_eye_data, example_behav_df, 908\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:24.333126Z",
     "iopub.status.busy": "2025-03-09T22:30:24.332719Z",
     "iopub.status.idle": "2025-03-09T22:30:24.355654Z",
     "shell.execute_reply": "2025-03-09T22:30:24.354728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 200, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj908_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for each subject\n",
    "    - for each feature type: generate a feature map\n",
    "\n",
    "- combination:\n",
    "    - subject - time point - feature combined\n",
    "    - a dictionary for mapping of feature id to feature and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:24.361006Z",
     "iopub.status.busy": "2025-03-09T22:30:24.360613Z",
     "iopub.status.idle": "2025-03-09T22:30:24.379425Z",
     "shell.execute_reply": "2025-03-09T22:30:24.378669Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_FEATURE_FOLDER = os.path.join(get_n_dir_up(CUR_PATH, 1), 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:24.383022Z",
     "iopub.status.busy": "2025-03-09T22:30:24.382635Z",
     "iopub.status.idle": "2025-03-09T22:30:24.402120Z",
     "shell.execute_reply": "2025-03-09T22:30:24.401364Z"
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash_configs(config, n_digits=6):\n",
    "    config_str = json.dumps(config, sort_keys=True)  # Ensure consistent order\n",
    "    config_hash = hashlib.sha256(config_str.encode('utf-8')).hexdigest()\n",
    "    config_hash = config_hash[:n_digits]\n",
    "    return config_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:24.405701Z",
     "iopub.status.busy": "2025-03-09T22:30:24.405414Z",
     "iopub.status.idle": "2025-03-09T22:30:24.429208Z",
     "shell.execute_reply": "2025-03-09T22:30:24.428422Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_combined_features_for_one_subjects(\n",
    "        feature_extractor_classes, feature_extractor_settings,\n",
    "        source_eyedata, source_behav_df, subj_id, overwrite=False):\n",
    "    \n",
    "    subj_result_folder = os.path.join(DEFAULT_FEATURE_FOLDER, f'{subj_id}')\n",
    "    if not os.path.exists(subj_result_folder):\n",
    "        os.makedirs(subj_result_folder)\n",
    "\n",
    "    # determine list of fe names\n",
    "    subj_fe_names = []\n",
    "    for fe_cls, fe_settings in zip(feature_extractor_classes, feature_extractor_settings):\n",
    "        fe_name = f'{fe_cls.__name__}_{hash_configs(fe_settings)}'\n",
    "        subj_fe_names.append(fe_name)\n",
    "\n",
    "    # check if it already exists\n",
    "    if not overwrite:\n",
    "        json_path = os.path.join(subj_result_folder, 'fe_names.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path) as f:\n",
    "                existing_fe_names = json.load(f)\n",
    "            if existing_fe_names == subj_fe_names:\n",
    "                print(f'Subject {subj_id} already processed')\n",
    "                return\n",
    "    \n",
    "    subj_features = []\n",
    "    subj_masked_df = None\n",
    "    for fe_cls, fe_settings in zip(feature_extractor_classes, feature_extractor_settings):\n",
    "        fe_name = f'{fe_cls.__name__}_{hash_configs(fe_settings)}'\n",
    "        fe = fe_cls(fe_settings)\n",
    "        features, _, subj_masked_df, _  = read_one_subject_feature(\n",
    "            fe, source_eyedata, source_behav_df, subj_id)\n",
    "        \n",
    "        fe_folder_path = os.path.join(subj_result_folder, fe_name)\n",
    "        if not os.path.exists(fe_folder_path):\n",
    "            os.makedirs(fe_folder_path)\n",
    "\n",
    "        # save the settings\n",
    "        config_path = os.path.join(fe_folder_path, 'settings.json')\n",
    "        with open(config_path, 'w') as fp:\n",
    "            json.dump(fe_settings, fp, indent=4)\n",
    "\n",
    "        # save the features\n",
    "        feature_path = os.path.join(fe_folder_path, 'features.npy')\n",
    "        np.save(feature_path, features)\n",
    "\n",
    "        # finally, add it to the combined features\n",
    "        subj_features.append(features)\n",
    "\n",
    "        \n",
    "    # create the combined features\n",
    "    subj_features = np.concatenate(subj_features, axis=-1)\n",
    "    # reshape: time x trials x n_feature\n",
    "    subj_features = np.transpose(subj_features, axes=(1, 0, 2))\n",
    "    # save the combined_features\n",
    "    subj_combined_feature_path = os.path.join(subj_result_folder, 'combined')\n",
    "    if not os.path.exists(subj_combined_feature_path):\n",
    "        os.makedirs(subj_combined_feature_path)\n",
    "\n",
    "    for tid in range(len(subj_features)):\n",
    "        np.save(\n",
    "            os.path.join(subj_combined_feature_path, f'{tid}.npy'), \n",
    "            subj_features[tid])\n",
    "\n",
    "    # save the behavior file\n",
    "    subj_behav_psth = os.path.join(subj_result_folder, 'behavior.csv')\n",
    "    subj_masked_df.to_csv(subj_behav_psth)\n",
    "\n",
    "    # save the list of settings\n",
    "    with open(os.path.join(subj_result_folder, 'fe_names.json'), 'w') as fp:\n",
    "        json.dump(subj_fe_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:24.432727Z",
     "iopub.status.busy": "2025-03-09T22:30:24.432305Z",
     "iopub.status.idle": "2025-03-09T22:30:26.281937Z",
     "shell.execute_reply": "2025-03-09T22:30:26.281020Z"
    }
   },
   "outputs": [],
   "source": [
    "REFORMATTED_XY = [create_xydata_from_df(df) for df in AllGazeCleans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:26.286433Z",
     "iopub.status.busy": "2025-03-09T22:30:26.285996Z",
     "iopub.status.idle": "2025-03-09T22:30:26.306786Z",
     "shell.execute_reply": "2025-03-09T22:30:26.306050Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_FE_CLASSES = [\n",
    "    GazeMeanExtractor,\n",
    "    GazeAngleFeatureExtractor,\n",
    "    GazeHeatmapFeatureExtractor,\n",
    "]\n",
    "\n",
    "DEFAULT_FE_SETTINGS = [\n",
    "    DEFAULT_MEAN_POS_SETTINGS,\n",
    "    DEFAULT_1D_VEC_SETTINGS,\n",
    "    DEFAULT_2D_VEC_SETTINGS,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:30:26.310243Z",
     "iopub.status.busy": "2025-03-09T22:30:26.309874Z",
     "iopub.status.idle": "2025-03-09T22:38:56.109268Z",
     "shell.execute_reply": "2025-03-09T22:38:56.107975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features for 908\n",
      "generating features for 909\n",
      "generating features for 910\n",
      "generating features for 912\n",
      "generating features for 913\n",
      "generating features for 914\n",
      "generating features for 915\n",
      "generating features for 916\n",
      "generating features for 917\n",
      "generating features for 918\n",
      "generating features for 920\n",
      "generating features for 921\n",
      "generating features for 922\n",
      "generating features for 927\n",
      "generating features for 929\n",
      "generating features for 930\n",
      "generating features for 931\n",
      "generating features for 932\n",
      "generating features for 933\n",
      "generating features for 934\n",
      "generating features for 935\n",
      "generating features for 937\n",
      "generating features for 938\n",
      "generating features for 939\n",
      "generating features for 940\n",
      "generating features for 941\n",
      "generating features for 942\n",
      "generating features for 943\n",
      "generating features for 944\n",
      "generating features for 945\n",
      "generating features for 946\n",
      "generating features for 947\n",
      "generating features for 948\n",
      "generating features for 949\n",
      "generating features for 950\n",
      "generating features for 951\n",
      "generating features for 952\n"
     ]
    }
   ],
   "source": [
    "OVERWRITE = True\n",
    "\n",
    "for batch_id, valid_subjs in enumerate(AllSubjBatches):\n",
    "    for subj in valid_subjs:\n",
    "        print(f'generating features for {subj}')\n",
    "        generate_combined_features_for_one_subjects(\n",
    "            feature_extractor_classes=DEFAULT_FE_CLASSES, \n",
    "            feature_extractor_settings=DEFAULT_FE_SETTINGS,\n",
    "            source_eyedata=REFORMATTED_XY[batch_id],\n",
    "            source_behav_df=AllPsyFull[batch_id], subj_id=subj,\n",
    "            overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eyetracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
