{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_n_dir_up(path, n):\n",
    "    for _ in range(n):\n",
    "        path = os.path.dirname(path)\n",
    "    return path\n",
    "\n",
    "CUR_PATH= os.path.abspath(\"__file__\")\n",
    "sys.path.append(os.path.join(get_n_dir_up(CUR_PATH, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DEFAULT_DATA_FOLDER = os.path.join(\n",
    "    get_n_dir_up(CUR_PATH, 3), 'data')\n",
    "with open(os.path.join(DEFAULT_DATA_FOLDER, 'QA.json')) as f:\n",
    "    qa_records = json.load(f)\n",
    "\n",
    "invalid_subjs = qa_records['invalid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FEATURE_FOLDER = os.path.join(\n",
    "    get_n_dir_up(CUR_PATH, 1), 'features')\n",
    "\n",
    "def load_subject_time_feature(subj, time_steps, normalize=True):\n",
    "    feature_loaded = []\n",
    "    subj_result_folder = os.path.join(DEFAULT_FEATURE_FOLDER, f'{int(subj)}')\n",
    "    subj_combined_feature_path = os.path.join(subj_result_folder, 'combined')\n",
    "    for tid in time_steps:\n",
    "        loaded = np.load(os.path.join(subj_combined_feature_path, f'{tid}.npy'))\n",
    "        feature_loaded.append(loaded)\n",
    "    features = np.mean(feature_loaded, axis=0) # time average\n",
    "\n",
    "    if normalize:\n",
    "        # Z-score normalization\n",
    "        means = np.mean(features, axis=0)  # Mean of each column\n",
    "        stds = np.std(features, axis=0)    # Standard deviation of each column\n",
    "        features = (features - means) / (stds + 1e-5)\n",
    "        \n",
    "    # also the behavior data\n",
    "    behavior_data = pd.read_csv(os.path.join(subj_result_folder, 'behavior.csv'))\n",
    "\n",
    "    return features, behavior_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjs = os.listdir(DEFAULT_FEATURE_FOLDER)\n",
    "all_subjs = [subj for subj in all_subjs if subj.isdigit()]\n",
    "all_subjs = [subj for subj in all_subjs if int(subj) not in invalid_subjs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, get the binned patterns using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert degrees to-from bin id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.distrib import color_smart_diff, color_smart_diff_outer\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "smart_diff = lambda x1, x2: color_smart_diff(x1, x2, vmin=-90, vmax=90)\n",
    "smart_diff_outer = lambda x1, x2: color_smart_diff_outer(x1, x2, vmin=-90, vmax=90)\n",
    "\n",
    "class DistFunctions:\n",
    "    \"\"\" define all distance function \"\"\"\n",
    "    @classmethod\n",
    "    def diff(cls, x1, x2, dist_name, pairwise):\n",
    "        if dist_name == 'cos':\n",
    "            return cls.cos_diff(x1, x2, pairwise)\n",
    "        elif dist_name == 'rad':\n",
    "            return cls.scaled_rad_diff(x1, x2, pairwise)\n",
    "        elif dist_name == 'euc':\n",
    "            return cls.euclidean_diff(x1, x2, pairwise)\n",
    "        else:\n",
    "            raise NotImplementedError(f'Unknown distance {dist_name}')\n",
    "\n",
    "    @classmethod\n",
    "    def cos_diff(cls, x1, x2, pairwise):\n",
    "        x1 = x1 / np.linalg.norm(x1, axis=-1, keepdims=True)\n",
    "        x2 = x2 / np.linalg.norm(x2, axis=-1, keepdims=True)\n",
    "        if pairwise:\n",
    "            dists = cdist(x1, x2, metric='cosine')\n",
    "        else:\n",
    "            similarity = np.sum(x1 * x2, axis=-1)\n",
    "            dists = 1 - similarity\n",
    "        return dists\n",
    "    \n",
    "    @classmethod\n",
    "    def euclidean_diff(cls, x1, x2, pairwise):\n",
    "        if pairwise:\n",
    "            dists = cdist(x1, x2, metric='euclidean')\n",
    "        else:\n",
    "            diffs = x1 - x2\n",
    "            dists = np.linalg.norm(diffs, axis=-1)\n",
    "        return dists\n",
    "    \n",
    "    @classmethod\n",
    "    def scaled_rad_diff(cls, x1, x2, pairwise):\n",
    "        if pairwise:\n",
    "            dists = np.abs(smart_diff_outer(x1, x2))\n",
    "        else:\n",
    "            dists = np.abs(smart_diff(x1, x2))\n",
    "        dists = np.deg2rad(dists)\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def z_normalize(x):\n",
    "    x = zscore(x, axis=0, nan_policy='omit')\n",
    "    x = np.nan_to_num(x) # avoid nan\n",
    "    return x\n",
    "\n",
    "class ConfidenceBinConversion:\n",
    "    def __init__(self, n_bins):\n",
    "        self.n_bins = n_bins\n",
    "        self.bins = np.linspace(0, 180, n_bins+1)\n",
    "        self.bin_center = (self.bins[1:] + self.bins[:-1]) / 2\n",
    "\n",
    "    def degree_to_bindiffs(self, degs):\n",
    "        diffs = DistFunctions.diff(\n",
    "            degs, self.bin_center, \n",
    "            dist_name='rad', pairwise=True)\n",
    "        return diffs\n",
    "    \n",
    "    # convert degree to discrete labels\n",
    "    def degree_to_binid(self, degs, dist_metric):\n",
    "        diffs = self.degree_to_bindiffs(degs)\n",
    "        bin_ids = np.argmin(diffs, axis=-1)\n",
    "        return bin_ids\n",
    "    \n",
    "    def binid_to_degree(self, bin_ids):\n",
    "        return self.bin_center[bin_ids]\n",
    "    \n",
    "    # convert to a distribution\n",
    "    def softmax_dist_to_distrib(self, dists, k):\n",
    "        distribs = np.exp(np.cos(dists) * k) # von-mises\n",
    "        distribs /= np.sum(distribs, axis=-1, keepdims=True)\n",
    "        return distribs\n",
    "    \n",
    "    def linear_dist_to_distrib(self, dists, k, offset=1e-2):\n",
    "        distribs = (dists+offset) ** k\n",
    "        distribs /= np.sum(distribs, axis=-1, keepdims=True)\n",
    "        return distribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ys_to_labels(multi_ys):\n",
    "    # ys shape: N x k\n",
    "\n",
    "def convert_ys_to_distribs(multi_ys):\n",
    "    # convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def degress_to_cos_sin(degrees):\n",
    "    # input: 0-180\n",
    "    degrees = degrees % 180\n",
    "    degrees = degrees * 2\n",
    "    rads = np.deg2rad(degrees)\n",
    "    c, s = np.cos(rads), np.sin(rads)\n",
    "    return c, s\n",
    "\n",
    "def cos_sin_to_degrees(cos_data, sin_data):\n",
    "    rads = np.arctan2(sin_data, cos_data)\n",
    "    degrees = np.rad2deg(rads)\n",
    "    degrees = degrees % 360\n",
    "    degrees = degrees / 2\n",
    "    return degrees\n",
    "\n",
    "def convert_stim_to_y(behav_df, stim_name, lmb):\n",
    "    # masking\n",
    "    stims = behav_df[stim_name].to_numpy()\n",
    "    mask = lmb(behav_df) & (~(np.isnan(stims)))\n",
    "    stims = stims[mask]\n",
    "    return mask, stims\n",
    "\n",
    "def prepare_continuous_regressor_xs_ys(subj, time_steps, stim_name, lmb, return_behav_df=False):\n",
    "    features, behav_df = load_subject_time_feature(subj, time_steps)\n",
    "    mask, ys = convert_stim_to_y(behav_df, stim_name, lmb)\n",
    "    features = features[mask]\n",
    "\n",
    "    if not return_behav_df:\n",
    "        return features, ys\n",
    "    else:\n",
    "        behav_df = behav_df[mask]\n",
    "        return features, ys, behav_df\n",
    "\n",
    "def svr_trigonometric_regression(X_train, y_train, X_test):\n",
    "    cos_train, sin_train = degress_to_cos_sin(y_train)\n",
    "\n",
    "    # Train SVR for cosine and sine components\n",
    "    # fit the model\n",
    "    svr_cos = SVR(kernel='rbf')\n",
    "    svr_sin = SVR(kernel='rbf')\n",
    "\n",
    "    svr_cos.fit(X_train, cos_train)\n",
    "    svr_sin.fit(X_train, sin_train)\n",
    "\n",
    "    # test the model\n",
    "    cos_pred = svr_cos.predict(X_test)\n",
    "    sin_pred = svr_sin.predict(X_test)\n",
    "    y_pred = cos_sin_to_degrees(cos_pred, sin_pred)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, for the test data, compute its difference to each 'pattern'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert diffs to confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demixture: decode the two distributions from it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eyetracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
